import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import gzip
import csv

class NameDateset(Dataset):#æ„å»ºæ•°æ®ç±»å‹å’Œå¯¹æ•°æ®çš„æ“ä½œ
    def __init__(self,is_train_set):
        filename='./names_train.csv.gz' if is_train_set else './names_test.csv.gz'
        #æ‰“å¼€è®­ç»ƒæ•°æ®é›†æˆ–è€…æµ‹è¯•é›†ï¼Œæ–‡ä»¶ç¬¬ä¸€åˆ—ä¸ºå§“åï¼Œç¬¬äºŒåˆ—ä¸ºå›½å®¶
        with gzip.open(filename,'rt') as f:#äºŒè¿›åˆ¶æ–¹å¼æ‰“å¼€gzæ–‡ä»¶ï¼Œå¹¶ä¸”è¿”å›ä¸€ä¸ªæ–‡ä»¶ç±»å‹
            reader=csv.reader(f)#è¯»å–csvæ–‡ä»¶
            rows=list(reader)#å°†è¯»å–çš„å†…å®¹æ¢æˆlistæ ¼å¼
            print(rows)
        self.names=[row[0] for row in rows]#åå­—åˆ—è¡¨
        self.len=len(self.names)#åå­—ä¸ªæ•°
        self.countrys=[row[1] for row in rows]#å›½å®¶åˆ—è¡¨
        self.country_list=list(sorted(set(self.countrys)))#æ„å»ºå›½å®¶å’Œç±»åˆ«åºå·ä¹‹é—´çš„å­—å…¸
        #å°†å›½å®¶å˜æˆå…ƒç»„ï¼ˆæ— é‡å¤ï¼‰å¹¶è¿›è¡Œæ’åºï¼Œè·å¾—æ’åºåçš„æ‰€æœ‰å›½å®¶ç±»åˆ«åˆ—è¡¨
        self.country_dict=self.getCountryDict()#è½¬æ¢ä¸ºè¯å…¸
        self.country_num=len(self.country_list)#æ‰€æœ‰å›½å®¶ç§ç±»

    def __getitem__(self, item):#æ ¹æ®ç´¢å¼•è·å–å¯¹åº”åå­—å’Œå›½å®¶ç±»åˆ«æ ‡ç­¾ï¼ˆæ•°å­—ï¼‰
        return self.names[item],self.country_dict[self.countrys[item]]

    def __len__(self):#è·å¾—æ•°æ®é›†çš„ä¸ªæ•°
        return self.len

    def getCountryDict(self):
        country_dict=dict()
        for idx,country_name in enumerate(self.country_list,0):
            country_dict[country_name]=idx
            #æ„å»ºä¸€ä¸ªå›½å®¶ä¸æ•°å­—å¯¹ï¼Œè¿™æ ·å¯ä»¥é€šè¿‡é¢„æµ‹å‡ºçš„æ•°å­—æ‰¾åˆ°å›½å®¶ç±»åˆ«
            #å¹¶ä¸”å¯¹åº”çš„æ•°å­—å®é™…ä¸Šæ˜¯å’Œlistçš„ä¸‹æ ‡ä¸€æ ·çš„
        return country_dict
    def idx2country(self,index):
        return self.country_list[index]
    def getCountriesNum(self):#è·å–æ‰€æœ‰å›½å®¶ç±»åˆ«æ•°
        return self.country_num

HIDDEN_SIZE=100#éšè—å±‚ï¼ˆä»¥åŠè¾“å‡ºï¼‰å¤§å°
BATCH_SIZE=256#æ¯ä¸€æ‰¹æ¬¡è®­ç»ƒçš„æ•°æ®é›†å¤§å°
N_LAYER=2#GRUå±‚æ•°
N_EPOCHS=50#è®­ç»ƒæ¬¡æ•°
N_CHARS=128 #ç”¨äºæ„å»ºåµŒå…¥å±‚embeddingï¼Œå› ä¸ºç”¨ASCIIç è¡¨ç¤ºå­—ç¬¦ï¼Œæ‰€ä»¥ä¸€ä¸ªonehoté•¿åº¦ä¸º128

trainSet=NameDateset(is_train_set=True)
trainLoader=DataLoader(trainSet,batch_size=BATCH_SIZE,shuffle=True)#åŠ è½½æ•°æ®
testSet=NameDateset(is_train_set=False)
testLoader=DataLoader(testSet,batch_size=BATCH_SIZE,shuffle=False)
#åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†

N_COUNTRY=trainSet.getCountriesNum()#å›½å®¶ç±»åˆ«æ•°é‡ï¼Œå†³å®šæœ€ç»ˆçš„è¾“å‡ºç»´åº¦

#æ„å»ºæ¨¡å‹
'''
è¾“å…¥ç»´åº¦
ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡: (ğ‘ ğ‘’ğ‘ğ¿ğ‘’ğ‘›, ğ‘ğ‘ğ‘¡ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›ğ‘†ğ‘–ğ‘§ğ‘’)
hidden: (nLayers * nDirections, batchSize, hiddenSize)
è¾“å‡ºç»´åº¦
output: (seqLen, batchSize, hiddenSize * nDirections)
hidden: (nLayers * nDirections, batchSize, hiddenSize)
'''

class RNNClassifier(torch.nn.Module):
    def __init__(self,input_size,hidden_size,output_size,n_layers=1,bidirectional=True):
        super(RNNClassifier,self).__init__()
        self.hidden_size=hidden_size
        self.n_layers=n_layers
        self.n_directions=2 if bidirectional else 1#æ–¹å‘æ•°
        self.embedding=torch.nn.Embedding(input_size,hidden_size)#éœ€è¦å°†åŸå§‹çš„onehotï¼ˆ128ç»´ï¼‰è½¬å˜ä¸ºåµŒå…¥å±‚ï¼Œç»´åº¦å¤§å°ä¸ºéšè—å±‚å¤§å°
        self.gru=torch.nn.GRU(hidden_size,hidden_size,n_layers,bidirectional=bidirectional)#è¾“å…¥è¾“å‡ºå¯ä»¥çœ‹åˆ°éƒ½æ˜¯hiddensize
        #å› ä¸ºåµŒå…¥å±‚çš„å¤„ç†ï¼Œbidirectionalä»£è¡¨æ˜¯åŒå‘GRUè¿˜æ˜¯å•å‘GRU
        self.fc=torch.nn.Linear(hidden_size*self.n_directions,output_size)
        #æ„å»ºä¸€ä¸ªçº¿æ€§å±‚

    def _init_hidden(self,batch_size):
        hidden=torch.zeros(self.n_layers*self.n_directions,batch_size,self.hidden_size)
        #åˆå§‹éšè—å±‚ä¸ºå…¨é›¶ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å±‚æ•°*æ˜¯å¦åŒå‘ï¼Œä»£è¡¨ç€åé¢ï¼ˆbatchsizeï¼Œhiddensizeï¼‰çš„å¤šå°‘
        return hidden

    def forward(self,input,seq_lengths):
        input=input.t()#è½¬ç½®ï¼Œå°†è¾“å…¥ä»ï¼ˆbatchsizeï¼Œseqlenthï¼‰è½¬å˜ä¸ºï¼ˆseqlength,batchsizeï¼‰ï¼Œå…¶ä¸­seqlengthå°±æ˜¯æ¯ä¸ªå•è¯çš„è¢«å¡«å……åçš„é•¿åº¦ï¼Œç°åœ¨æ˜¯æ¯ä¸€åˆ—ä»£è¡¨ä¸€ä¸ªå•è¯äº†
        batch_size=input.size(1)#ä»0å¼€å§‹ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯batchsize
        hidden=self._init_hidden(batch_size)
        embedding=self.embedding(input)#è¿è¡Œåä¸ºï¼ˆseqlengthï¼Œbatchsizeï¼Œhiddesizeï¼‰ï¼Œå³å°†æ¯ä¸€ä¸ªä¸‹æ ‡ç”¨ï¼ˆASCIIçš„è¡¨ç¤ºï¼‰è½¬å˜ä¸ºhiddensizeå¤§å°çš„åµŒå…¥è¡¨ç¤ºï¼Œ
        # åŸæœ¬æ¯ä¸ªä¸‹æ ‡éœ€è¦ç”¨onehotè¡¨ç¤ºï¼ˆå¯ä»¥çœ‹åšå®¢åŠ æ·±äº†è§£ï¼‰

        #pack them up
        gru_input=torch.nn.utils.rnn.pack_padded_sequence(embedding,seq_lengths)
        #æŠŠæ‰€æœ‰éé›¶çš„ï¼ˆéå¡«å……çš„ï¼‰æ•°æ®éƒ½æ‰“åŒ…æˆä¸€ä¸ªäºŒä½çŸ©é˜µï¼Œå°±æ˜¯å°†ä¸€ä¸ªbatchsizeçš„å…¨æ‰“åŒ…
        # ï¼ˆç›¸å½“äºå°†è¿™ä¸ªç»´åº¦æ‰å¹³åŒ–äº†ï¼Œä½†è¿™å¿…é¡»è¦æ±‚æŒ‰éé›¶å€¼ä¸ªæ•°ç”±å¤§åˆ°å°åœ¨batchsizeç»´åº¦ä¸Šä»å·¦åˆ°å³æ’åˆ—ï¼‰ï¼Œè¿™ä½¿ç”¨make_Tensorå®ç°
        #è¿™ä¸ªæ’åˆ—åœ¨é€å…¥embeddingå‰å°±è¦è¿›è¡Œï¼ŒåŒæ—¶ä¼šä¸“é—¨è®°å½•ä¸‹æ¥æ¯ä¸ªå•è¯çš„é•¿åº¦ï¼Œä»¥ä¾¿çŸ¥é“æ¯ä¸ªæ—¶åˆ»è¯»å–å¤šå°‘æ•°æ®
        output,hidden=self.gru(gru_input,hidden)
        if self.n_directions==2:
            hidden_cat=torch.cat([hidden[-1],hidden[-2]],dim=1)#å¦‚æœæœ‰ä¸¤ä¸ªæ–¹å‘ï¼Œå°±å°†éšè—å±‚æ‹¼æ¥èµ·æ¥
        else:
            hidden_cat=hidden[-1]

        fc_output=self.fc(hidden_cat)#æœ€åé€šè¿‡çº¿æ€§å±‚å˜æˆæƒ³è¦çš„ç»´åº¦ï¼ˆåˆ†ç±»æ•°128ï¼‰
        return fc_output

#å°†æ•°æ®è½¬åŒ–ä¸ºTensorï¼Œéœ€è¦å¡«å……0ä»¥åŠæŒ‰åå­—é•¿åº¦è¿›è¡Œé™åºæ’åº

def name2list(name):
    arr=[ord(c) for c in name]#å°†åå­—çš„æ¯ä¸ªå­—ç¬¦æ¢æˆå¯¹åº”ASCIIå€¼çš„åˆ—è¡¨
    return arr,len(arr)

def make_tensors(names,countries):
    sequences_and_lengths=[name2list(name) for name in names]#æŠŠæ‰€æœ‰åå­—è¿›è¡Œå˜æ¢
    name_sequences=[s1[0] for s1 in sequences_and_lengths]#å»é™¤æ‰€æœ‰çš„è½¬æ¢åçš„åå­—
    seq_lengths=torch.LongTensor([s1[1] for s1 in sequences_and_lengths])#å–å‡ºæ‰€æœ‰åå­—çš„é•¿åº¦å¹¶è½¬ä¸ºä¸ºåˆ—è¡¨ï¼Œç„¶åè½¬æ¢æˆtensor
    countries=countries.long()
    # make tensor of name, BatchSize * seqLen
    # ä»–è¿™é‡Œè¡¥é›¶çš„æ–¹å¼å…ˆå°†æ‰€æœ‰çš„0 Tensorç»™åˆå§‹åŒ–å‡ºæ¥ï¼Œç„¶ååœ¨æ¯è¡Œå‰é¢å¡«å……æ¯ä¸ªåå­—
    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()#ä»¥æœ€é•¿å•è¯é•¿åº¦ä¸ºåŸºå‡†è¿›è¡Œå¡«å……
    # print("seq_lengths.max:", seq_lengths.max())
    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):
        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)#å°†å‰é¢éƒ¨åˆ†å¡«ä¸Šåå­—è¡¨ç¤º

    # sort by length to use pack_padded_sequence
    # å°†åå­—é•¿åº¦é™åºæ’åˆ—ï¼Œå¹¶ä¸”è¿”å›é™åºä¹‹åçš„é•¿åº¦åœ¨åŸtensorä¸­çš„å°æ ‡perm_idx
    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)
    # è¿™ä¸ªTensorä¸­çš„ç±»ä¼¼äºåˆ—è¡¨ä¸­åˆ‡ç‰‡çš„æ–¹æ³•ç¥å¥‡å•Šï¼Œç›´æ¥è¿”å›ä¸‹æ ‡å¯¹åº”çš„å…ƒç´ ï¼Œç›¸ç­‰äºæ’åºäº†
    seq_tensor = seq_tensor[perm_idx]
    countries = countries[perm_idx]

    # è¿”å›æ’åºä¹‹ååå­—Tensorï¼Œæ’åºä¹‹åçš„åå­—é•¿åº¦Tensorï¼Œæ’åºä¹‹åçš„å›½å®¶åå­—Tensor
    return seq_tensor, seq_lengths, countries

classifier=RNNClassifier(N_CHARS,HIDDEN_SIZE,N_COUNTRY,N_LAYER)

criterion=torch.nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(classifier.parameters(),lr=0.001)

import time
import math

def trainModel():
    def time_since(since):
        s=time.time()-since
        m=math.floor(s/60)
        s-=m*60
        return  '%d %ds' %(m,s)
    total_loss=0
    for i,(names,countries) in enumerate(trainLoader,1):
        inputs,seq_lengths,target=make_tensors(names,countries)#æ„å»ºå¼ é‡
        #output =classifier(inputs,seq_lengths)
        # æ³¨æ„è¾“å‡ºå’Œç›®æ ‡çš„ç»´åº¦ï¼šShape: torch.Size([256, 18]) torch.Size([256])
        output = classifier(inputs, seq_lengths)

        loss=criterion(output,target)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss+=loss.item()
        if i%10==0:
            print(f'[{time_since(start)}] Epoch {epoch} ', end='')
            print(f'[{i * len(inputs)}/{len(trainSet)}] ', end='')
            print(f'loss={total_loss / (i * len(inputs))}')
    return total_loss

def testModel():
    correct=0
    total=len(testSet)
    print("evaluating trained model ... ")
    with torch.no_grad():
        for i,(names,countries) in enumerate(testLoader):
            inputs, seq_lengths, target = make_tensors(names, countries)
            output = classifier(inputs, seq_lengths)
            # æ³¨æ„è¿™ä¸ªkeepdimçš„ä½¿ç”¨ï¼Œä¸ºäº†ç›´æ¥å’Œtargetè®¡ç®—loss
            pred = output.max(dim=1, keepdim=True)[1]
            # æ³¨æ„è¿™ä¸ªview_as å’Œ eq
            correct += pred.eq(target.view_as(pred)).sum().item()

        percent = '%.2f' % (100 * correct / total)
        print(f'Test set: Accuracy {correct}/{total} {percent}%')

    return correct / total

N_EPOCHS=50
start=time.time()
print("Training for %d epochs..." % N_EPOCHS)
acc_list = []
for epoch in range(1,N_EPOCHS+1):
    trainModel()
    acc=testModel()
    acc_list.append(acc)


import matplotlib.pyplot as plt
import numpy as np

epoch = np.arange(1, len(acc_list) + 1)
acc_list = np.array(acc_list)
plt.plot(epoch, acc_list)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.grid()
plt.show()